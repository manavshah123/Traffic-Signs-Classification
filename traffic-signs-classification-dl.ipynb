{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ‚õîÔ∏è Traffic Signs Classification with Resnet50","metadata":{}},{"cell_type":"markdown","source":"<h2>What is Transfer Learning</h2>\n<center><img width=600px src = \"https://ruder.io/content/images/2017/03/transfer_learning_setup.png\" alt=\"Transfer Learning\"></center>\n\n<p>Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. We try to store this knowledge gained in solving the source task in the source domain and apply it to our problem of interest as can be seen in Figure above </p>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"resnet\"><h3>What is A ResNet 50?</h3></div>\n<p></p>\n<center><img src=\"https://i.stack.imgur.com/gI4zT.png\" width=600px alt=\"ResNet\"></center>\n<p></p>\n<p>\nResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully. Prior to ResNet training very deep neural networks was difficult due to the problem of vanishing gradients.</p>","metadata":{}},{"cell_type":"markdown","source":"# üì• Importing needed libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n\nimport tensorflow as tf\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential # A Sequential model is appropriate for a plain \n#stack of layers where each layer has exactly one input tensor and one output tensor.\n\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape, Lambda\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.applications import ResNet50\n\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('../input'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-13T14:59:31.477010Z","iopub.execute_input":"2021-12-13T14:59:31.477322Z","iopub.status.idle":"2021-12-13T14:59:33.454093Z","shell.execute_reply.started":"2021-12-13T14:59:31.477267Z","shell.execute_reply":"2021-12-13T14:59:33.453418Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Fixed for our Categories classes\nNUM_CLASSES = 43\n\n# Fixed for Categories color images\nCHANNELS = 3\n\nIMAGE_RESIZE = 224\n#first resize all the images to 224 shape and then learn\n\nRESNET50_POOLING_AVERAGE = 'avg'\n\nDENSE_LAYER_ACTIVATION = 'softmax'\n#Softmax converts a vector of values to a probability distribution.The elements of the output vector are in range (0, 1) and sum to 1.\n\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\n#categorical_crossentropy: Used as a loss function for multi-class classification model \n#where there are two or more output labels. The output label is assigned one-hot category encoding value in form of 0s and 1.\n\n# Common accuracy metric for all outputs, but can use different metrics for different output\nLOSS_METRICS = ['accuracy']\n\n# Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. \n# Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training \n# once the model performance stops improving on a hold out validation dataset.\n# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\nNUM_EPOCHS = 10\nEARLY_STOP_PATIENCE = 3\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 10\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\nBATCH_SIZE_TRAINING = 100\nBATCH_SIZE_VALIDATION = 100\n\n# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\nBATCH_SIZE_TESTING = 1","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:59:33.456149Z","iopub.execute_input":"2021-12-13T14:59:33.456468Z","iopub.status.idle":"2021-12-13T14:59:33.464786Z","shell.execute_reply.started":"2021-12-13T14:59:33.456416Z","shell.execute_reply":"2021-12-13T14:59:33.463976Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# üìÇ Loading dataset data2.pickle with RGB examples","metadata":{}},{"cell_type":"code","source":"# Opening file for reading in binary mode\nwith open('../input/traffic-signs-preprocessed/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for using in Keras\n# num_classes: Total number of classes. If nothing is mentioned, it considers \n# the largest number of the input vector and adds 1, to get the number of classes.Its default value is \"None\".\n\n# to_categorical represent different categories\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\n# transpose function is axes of data\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:59:33.466035Z","iopub.execute_input":"2021-12-13T14:59:33.466349Z","iopub.status.idle":"2021-12-13T14:59:47.397517Z","shell.execute_reply.started":"2021-12-13T14:59:33.466297Z","shell.execute_reply":"2021-12-13T14:59:47.396715Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# üí´ Showing some examples","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\n\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    # ceil() is a mathematical function that returns the ceil of the elements of array. The ceil of the scalar x is the smallest integer i, such that i >= x\n    grid_size = int(np.ceil(np.sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    # Return a new array of given shape and type, filled with zeros.\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    \n    for y in range(grid_size):\n        x0, x1 = 0, W\n        \n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) / (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:81, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\n# A UINT8 is an 8-bit unsigned integer\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\n# GCF means Get the current figure.\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('training_examples.png')\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:49:36.443214Z","iopub.execute_input":"2021-12-13T15:49:36.443547Z","iopub.status.idle":"2021-12-13T15:49:36.877534Z","shell.execute_reply.started":"2021-12-13T15:49:36.443496Z","shell.execute_reply":"2021-12-13T15:49:36.876836Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# üèóÔ∏è Building model of Resnet50 (Transfer Learning)","metadata":{}},{"cell_type":"code","source":"resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:59:47.865593Z","iopub.execute_input":"2021-12-13T14:59:47.866051Z","iopub.status.idle":"2021-12-13T14:59:47.870454Z","shell.execute_reply.started":"2021-12-13T14:59:47.865864Z","shell.execute_reply":"2021-12-13T14:59:47.869405Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img_size = (224,224)\nmodel = Sequential()\n# ‚Äúinclude_top‚Äù argument can be set to False, in which case the fully-connected output layers of the model used to make predictions is not loaded, allowing a new output layer to be added and trained. \n\nmodel.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\nmodel.add(Dropout(0.1))\n# The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\nmodel.layers[2].trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:59:47.872087Z","iopub.execute_input":"2021-12-13T14:59:47.872597Z","iopub.status.idle":"2021-12-13T15:00:05.552683Z","shell.execute_reply.started":"2021-12-13T14:59:47.872435Z","shell.execute_reply":"2021-12-13T15:00:05.551867Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# ü§è Training Model","metadata":{}},{"cell_type":"code","source":"from keras import optimizers\n\n# Stochastic gradient descent optimizer.\n\n# Includes support for momentum, learning rate decay, and Nesterov momentum.\n\n# Arguments\n\n# lr: float >= 0. Learning rate.\n# momentum: float >= 0. Parameter updates momentum.\n# decay: float >= 0. Learning rate decay over each update.\n# nesterov: boolean. Whether to apply Nesterov momentum.\n    \nsgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nmodel.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:00:05.554099Z","iopub.execute_input":"2021-12-13T15:00:05.554396Z","iopub.status.idle":"2021-12-13T15:00:05.601877Z","shell.execute_reply.started":"2021-12-13T15:00:05.554347Z","shell.execute_reply":"2021-12-13T15:00:05.601282Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(data['x_train'], data['y_train'], validation_data =(data['x_validation'], data['y_validation']), epochs = 20, batch_size = 1000)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:00:05.603279Z","iopub.execute_input":"2021-12-13T15:00:05.603724Z","iopub.status.idle":"2021-12-13T15:07:31.136546Z","shell.execute_reply.started":"2021-12-13T15:00:05.603671Z","shell.execute_reply":"2021-12-13T15:07:31.135762Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n      format(10, max(hist.history['acc']), max(hist.history['val_acc'])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:07:31.138158Z","iopub.execute_input":"2021-12-13T15:07:31.138471Z","iopub.status.idle":"2021-12-13T15:07:31.144156Z","shell.execute_reply.started":"2021-12-13T15:07:31.138421Z","shell.execute_reply":"2021-12-13T15:07:31.143421Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# üìà Plotting results","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\nplt.plot(hist.history['acc'], '-o', linewidth=3.0)\nplt.plot(hist.history['val_acc'], '-o', linewidth=3.0)\nplt.title('Overfitting small data', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Accuracy', fontsize=20)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('overfitting_small_data.png')\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:07:31.145383Z","iopub.execute_input":"2021-12-13T15:07:31.145803Z","iopub.status.idle":"2021-12-13T15:07:31.527224Z","shell.execute_reply.started":"2021-12-13T15:07:31.145753Z","shell.execute_reply":"2021-12-13T15:07:31.526360Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# üñºÔ∏è Predicting with one image from test dataset","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][100:101]\nprint(x_input.shape)\ny_input = data['y_test'][100:101]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\n# Showing the plot\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model.predict(x_input)\nprint(scores.shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('../input/traffic-signs-preprocessed/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:07:31.531789Z","iopub.execute_input":"2021-12-13T15:07:31.532225Z","iopub.status.idle":"2021-12-13T15:07:33.181794Z","shell.execute_reply.started":"2021-12-13T15:07:31.532059Z","shell.execute_reply":"2021-12-13T15:07:33.180467Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}